{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54a1e37e",
   "metadata": {},
   "source": [
    "# Voice leading reinforcement learning agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77219ad5",
   "metadata": {},
   "source": [
    "## Introduction.\n",
    "[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45011e38",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{E}[\\text{return}|\\alpha, s]\n",
    "\\ =\\ \n",
    "\\text{reward}+\\underset{\\ \\beta\\ \\in\\ \\mathcal{A}_{\\alpha(s)}\\!\\!}{\\text{max}}\\mathbb{E}\\left[\\text{return}|\\beta, \\alpha(s)\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "v(\\alpha, s)\n",
    "\\ =\\ \n",
    "R(\\alpha)+\\underset{\\ \\beta\\ \\in\\ \\mathcal{A}_{\\alpha(s)}\\!\\!}{\\text{max}}v\\big(\\beta, \\alpha(s)\\big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "526142e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from inspect import isfunction\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74896442-e50a-4b35-9aa4-d999c4168467",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0b5828",
   "metadata": {},
   "source": [
    "## Classes for various aspects of music theory.\n",
    "The various Python classes we define in this section collect important aspects of music theory relevant to problem of voice leading. Using MIDI standard encoding for instance, every note in the scale can be assigned an integer value between $0$ and $127$. In this way, a solution to any voice leading problem can be encoded completely numerically. However, the reward functions for the sequence of step-by-step actions that constitute a proposed solution to a voice leading problem depend on musical theoretical considerations. We will use the classes we define in the present section in order to evaluation remards for our agent's actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd98d1ee",
   "metadata": {},
   "source": [
    "### Classes related to harmony and melody."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861a6c70",
   "metadata": {},
   "source": [
    "#### Class: `Notes`\n",
    "Parent(s): *none*\n",
    "\n",
    "Constructor arguments: *none*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ddc7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Notes():\n",
    "    def __init__(self):\n",
    "        \n",
    "        valmod12_to_class = {0: ('C', 'C'),\n",
    "            1: ('C♯', 'D♭'),\n",
    "            2: ('D', 'D'),\n",
    "            3: ('D♯', 'E♭'),\n",
    "            4: ('E', 'E'),\n",
    "            5: ('F', 'F'),\n",
    "            6: ('F♯', 'G♭'),\n",
    "            7: ('G', 'G'),\n",
    "            8: ('G♯', 'A♭'),\n",
    "            9: ('A', 'A'),\n",
    "            10: ('A♯', 'B♭'),\n",
    "            11: ('B', 'B')}\n",
    "        self.valmod12_to_class = valmod12_to_class\n",
    "        \n",
    "        all_note_class_names = []\n",
    "        for key in self.valmod12_to_class:\n",
    "            class_pair = self.valmod12_to_class[key]\n",
    "            all_note_class_names.append(class_pair[0])\n",
    "            all_note_class_names.append(class_pair[1])\n",
    "        self.all_note_class_names = all_note_class_names\n",
    "        \n",
    "        class_to_valmod12 = {}\n",
    "        for key in self.valmod12_to_class:\n",
    "            class_pair = self.valmod12_to_class[key]\n",
    "            for entry in class_pair:\n",
    "                class_to_valmod12.update({entry: key})\n",
    "        self.class_to_valmod12 = class_to_valmod12\n",
    "        \n",
    "        value_to_class = {}\n",
    "        for value in range(128):\n",
    "            valmod12 = value%12\n",
    "            class_pair = self.valmod12_to_class[valmod12]\n",
    "            value_to_class.update({value: class_pair})\n",
    "        self.value_to_class = value_to_class\n",
    "        \n",
    "        note_to_value = {}\n",
    "        for value in self.value_to_class:\n",
    "            class_pair = self.value_to_class[value]\n",
    "            sharp_class = class_pair[0]\n",
    "            flat_class = class_pair[1]\n",
    "            valmod12 = value%12\n",
    "            octave = -1 + int((value - valmod12)/12)\n",
    "            note_to_value.update({sharp_class+'{}'.format(octave): value})\n",
    "            note_to_value.update({flat_class+'{}'.format(octave): value})\n",
    "        self.note_to_value = note_to_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42276ae-9e63-41fd-9fe3-8588f0624919",
   "metadata": {},
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffd82563-f694-44bc-b0cb-c8e19ba9b9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "notes = Notes()\n",
    "print(notes.valmod12_to_class[8][0] == 'G♯')\n",
    "print(notes.class_to_valmod12['E♭'] == 3)\n",
    "print(notes.value_to_class[54] == ('F♯', 'G♭'))\n",
    "print(notes.note_to_value['E♭2'] == 39)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538a25c5",
   "metadata": {},
   "source": [
    "#### Class: `Scales`\n",
    "Parent(s):\n",
    "\n",
    "Constructor arguments: *none*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaca2af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scales():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Construct modern mode degrees, ascending and descending, as attributes:\n",
    "        self.long_step_sequence = [2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2]\n",
    "        \n",
    "        self.mode_start = {'Ionian': 0,\n",
    "            'Dorian': 1,\n",
    "            'Phrygian': 2,\n",
    "            'Lydian': 3,\n",
    "            'Mixolydian': 4,\n",
    "            'Aeolian': 5,\n",
    "            'Locrian': 6}\n",
    "        \n",
    "        modern_mode_steps = {}\n",
    "        for key, value in self.mode_start.items():\n",
    "            mode = key\n",
    "            start_position = value\n",
    "            current_mode_steps = [self.long_step_sequence[i] for i in range(start_position, start_position+7)]\n",
    "            modern_mode_steps.update({mode: current_mode_steps})\n",
    "        self.modern_mode_steps = modern_mode_steps\n",
    "        \n",
    "        updown_mode_degrees = {}\n",
    "        for key, value in self.modern_mode_steps.items():\n",
    "            mode = key\n",
    "            step_sequence = value\n",
    "            degree_sequence = [0]\n",
    "            for i, step in enumerate(step_sequence):\n",
    "                scale_degree = degree_sequence[i]\n",
    "                new_scale_degree = (scale_degree + step)%12\n",
    "                degree_sequence.append(new_scale_degree)\n",
    "                rev_degree_sequence = degree_sequence[::-1]\n",
    "            updown_mode_degrees.update({mode: {'up': copy.deepcopy(degree_sequence),\n",
    "                                     'down': copy.deepcopy(rev_degree_sequence)}})\n",
    "        \n",
    "        # Construct Major mode degrees, ascending and descending, as attributes:\n",
    "        major_updown = updown_mode_degrees['Ionian']\n",
    "        updown_mode_degrees.update({'Major': copy.deepcopy(major_updown)})\n",
    "\n",
    "        # Construct Natural minor mode degrees, ascending and descending, as attributes:\n",
    "        natural_minor_updown = updown_mode_degrees['Aeolian']\n",
    "        updown_mode_degrees.update({'Natural_minor': copy.deepcopy(natural_minor_updown)})\n",
    "\n",
    "        # Construct Harmonic minor mode degrees, ascending and descending, as attributes:\n",
    "        harmonic_minor_steps = [2, 1, 2, 2, 1, 3, 1]\n",
    "        harmonic_minor_degree_sequence = [0]\n",
    "        for i, step in enumerate(harmonic_minor_steps):\n",
    "            scale_degree = harmonic_minor_degree_sequence[i]\n",
    "            new_scale_degree = (scale_degree + step)%12\n",
    "            harmonic_minor_degree_sequence.append(new_scale_degree)\n",
    "            rev_harmonic_minor_degree_sequence = harmonic_minor_degree_sequence[::-1]\n",
    "        updown_mode_degrees.update({'Harmonic_minor': {'up': copy.deepcopy(harmonic_minor_degree_sequence),\n",
    "                                                     'down': copy.deepcopy(rev_harmonic_minor_degree_sequence)}})\n",
    "\n",
    "        # Construct Melodic minor mode degrees, ascending and descending, as attributes:\n",
    "        melodic_minor_steps_up = [2, 2, 1, 2, 2, 2, 1]\n",
    "        melodic_minor_degrees_up = [0]\n",
    "        for i in range(7):\n",
    "            current_degree = melodic_minor_degrees_up[i]\n",
    "            next_degree = (current_degree + melodic_minor_steps_up[i])%12\n",
    "            melodic_minor_degrees_up.append(next_degree)\n",
    "        melodic_minor_steps_down = [2, 2, 1, 2, 1, 2, 2]\n",
    "        melodic_minor_degrees_down = [0]\n",
    "        for i in range(7):\n",
    "            current_degree = melodic_minor_degrees_down[i]\n",
    "            next_degree = (current_degree - melodic_minor_steps_down[i])%12\n",
    "            melodic_minor_degrees_down.append(next_degree)\n",
    "        updown_mode_degrees.update({'Melodic_minor': {'up': copy.deepcopy(melodic_minor_degrees_up),\n",
    "                                                    'down': copy.deepcopy(melodic_minor_degrees_down)}})\n",
    "\n",
    "        # Combine all ascending and descending mode degrees into attribute dictionary:\n",
    "        self.updown_mode_degrees = updown_mode_degrees\n",
    "\n",
    "        # Collect all modes constructed as list attribute:\n",
    "        mode_list = [key for key in self.updown_mode_degrees]\n",
    "        self.mode_list = mode_list\n",
    " \n",
    "    # Method for querying the ascending/descending mode degree dictionary attribute:\n",
    "    def updown_degrees(self, mode):\n",
    "        assert mode in self.mode_list\n",
    "        output = self.updown_mode_degrees[mode]\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b425b5",
   "metadata": {},
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f8baf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = Scales()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c233e02",
   "metadata": {},
   "source": [
    "#### Class: `Key`\n",
    "Parent(s):\n",
    "\n",
    "Constructor arguments:\n",
    "* *root* = `'C'`, \n",
    "* *mode* = `'Major'`\n",
    "\n",
    "**Important.** The constructor for the `Key` class constructs an instance each of the `Notes` and `Scales` classes as attributes of `Key`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73ab95c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Key():\n",
    "    def __init__(self,\n",
    "                 root = 'C',\n",
    "                 mode = 'Major'):\n",
    "        \n",
    "        self.notes = Notes()\n",
    "        self.scales = Scales()\n",
    "        \n",
    "        assert root in self.notes.all_note_class_names\n",
    "        assert mode in self.scales.mode_list\n",
    "        \n",
    "        self.root_class = root\n",
    "        self.root_valmod12 = self.notes.class_to_valmod12[self.root_class]\n",
    "        \n",
    "        self.mode = mode\n",
    "        \n",
    "        self.scale_degrees = self.scales.updown_degrees(mode = self.mode)\n",
    "        self.up_degrees = self.scale_degrees['up']\n",
    "        self.triad_degrees = [self.up_degrees[i] for i in [0,2,4]]\n",
    "        self.triad_valsmod12 = [(self.root_valmod12 + degree)%12 for degree in self.triad_degrees]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ca6f4e",
   "metadata": {},
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "810e6ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "key = Key(root = 'E', mode = 'Melodic_minor')\n",
    "print(key.triad_degrees == [0, 4, 7])\n",
    "print(key.triad_valsmod12 == [4, 8, 11])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dad6e7",
   "metadata": {},
   "source": [
    "## Classes for rewards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec9227e",
   "metadata": {},
   "source": [
    "### Classes for progress-to-final-interval rewards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed019712",
   "metadata": {},
   "source": [
    "#### Class: `SmallProgtoFinScheme`\n",
    "Parent(s): *none*\n",
    "\n",
    "Constructor arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cc82ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallProgtoFinSchema():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def reward(self,\n",
    "        chord_0 = np.array([73, 76]),\n",
    "        chord_1 = np.array([72, 74]),\n",
    "        final_chord = np.array([35, 45])):\n",
    "        \n",
    "        assert len(chord_0) == len(chord_1) == len(final_chord)\n",
    "        \n",
    "        n = len(final_chord)\n",
    "        \n",
    "        centroid_0 = np.sum(chord_0)/n\n",
    "        centroid_1 = np.sum(chord_1)/n\n",
    "        final_centroid = np.sum(final_chord)/n\n",
    "        \n",
    "        needed_change = final_centroid - centroid_0\n",
    "        #needed_direction = np.sign(needed_change)\n",
    "        \n",
    "        actual_change = centroid_1 - centroid_0\n",
    "        #actual_direction = np.sign(actual_change)\n",
    "        \n",
    "        if actual_change == 0.:\n",
    "            change_ratio = -100.\n",
    "        else:\n",
    "            change_ratio = needed_change/actual_change\n",
    "        \n",
    "        return change_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0be524f",
   "metadata": {},
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4788c9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.0\n",
      "-1.0\n",
      "-100.0\n"
     ]
    }
   ],
   "source": [
    "small_prog_to_fin_scheme = SmallProgtoFinSchema()\n",
    "\n",
    "print(small_prog_to_fin_scheme.reward(chord_0 = np.array([73, 76]),\n",
    "                                      chord_1 = np.array([73, 75]),\n",
    "                                      final_chord = np.array([35, 45])))\n",
    "\n",
    "print(small_prog_to_fin_scheme.reward(chord_0 = np.array([73, 76]),\n",
    "                                      chord_1 = np.array([73, 75]),\n",
    "                                      final_chord = np.array([73, 77])))\n",
    "\n",
    "print(small_prog_to_fin_scheme.reward(chord_0 = np.array([73, 76]),\n",
    "                                      chord_1 = np.array([73, 76]),\n",
    "                                      final_chord = np.array([74, 78])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f37d18-523e-48f6-9e40-d71f0edab83c",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d18b98",
   "metadata": {},
   "source": [
    "## Agent classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f0ecc7-ffb0-42e2-ac89-5d34fadd0bb9",
   "metadata": {},
   "source": [
    "#### Function: `randinterval`\n",
    "Arguments: *none*\n",
    "\n",
    "**Remark.** It occurs to me that I was introducing inductive biases into the agent with the way I had this `randchord` function written. I was randomly selecting an `np.array` $[i_0, i_1, \\dots, i_{n-1}]$ by selecting $i_0$, then selecting $i_1>i_0$, and so on, within a given range. With a bit of thought though, it becomes clear that this method is not *independent and identically distributed* (iid). For instance, if we draw a pair or integers $i_0 < i_1$ from the set $[0,1,2]$ using this method, then the probability density ends up being\n",
    "$$\\rho([0,1])=\\tfrac{1}{4},\\ \\ \\ \\ \\ \\ \\rho([0,2])=\\tfrac{1}{4},\\ \\ \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ \\ \\ \\rho([1,2])=\\tfrac{1}{2}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d71dbce-b106-4710-aa4e-708cf87eddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomChord():\n",
    "    def __init__(self, chord_size = 3, lower_limit = 0, upper_limit = 127):\n",
    "        assert isinstance(chord_size, int)\n",
    "        assert chord_size > 0\n",
    "        assert isinstance(lower_limit, int)\n",
    "        assert isinstance(upper_limit, int)\n",
    "        assert lower_limit <= upper_limit\n",
    "        assert chord_size <= upper_limit - lower_limit + 1\n",
    "        \n",
    "        self.chord_size = chord_size\n",
    "        self.lower_limit = lower_limit\n",
    "        self.upper_limit = upper_limit\n",
    "        \n",
    "        admissible_chords = [[k] for k in range(self.lower_limit, self.upper_limit + 2 - self.chord_size)]\n",
    "        for i in range(1, self.chord_size):\n",
    "            new_admissible_chords = []\n",
    "            for running_chord in admissible_chords:\n",
    "                new_lower_limit = running_chord[-1] + 1\n",
    "                for k in range(new_lower_limit, self.upper_limit + 2 - self.chord_size + i):\n",
    "                    new_chord = running_chord + [k] \n",
    "                    new_admissible_chords.append(new_chord)\n",
    "            admissible_chords = new_admissible_chords\n",
    "        self.admissible_chords = admissible_chords\n",
    "        \n",
    "    \n",
    "    def sample(self):\n",
    "        chord = random.choice(self.admissible_chords)\n",
    "        return chord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c8c161-d8cb-494c-9b44-a6226a9da862",
   "metadata": {},
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9216dd2e-9317-4e90-9f01-b78f8c2fb258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "random_chord = RandomChord(chord_size = 3, lower_limit = 0, upper_limit = 5)\n",
    "\n",
    "for i in range(4):\n",
    "    output = random_chord.sample()\n",
    "    print(output[0]<output[1]<output[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b00550-aed5-489d-a73c-9ca72c391351",
   "metadata": {},
   "source": [
    "#### Class: `ActionValue_Spec1`\n",
    "Parent(s): `torch.nn.Module`\n",
    "\n",
    "Constructor arguments:\n",
    "* *layer_count* = `6`\n",
    "* *layer_features* = `1000`\n",
    "\n",
    "**Remark: `ReLU` versus `Softmax`.** Because we're implicitly using the *greedy policy*, which, at each state $s$, always selects the action $\\alpha$ that maximizes the action-value $v_{\\text{greed}}(s,\\alpha)$, it might appear that the neural network that approximates $v_{\\text{greed}}(s,\\alpha)$ should use *softmax* activation at its final layer. However, the specific value of $v_{\\text{greed}}(s,\\alpha)$ is also important. This activation function $v_{\\text{greed}}(s,\\alpha)$ is supposed to output the *excpected return* $\\mathbb{E}_{\\text{greed}}[G|\\alpha,\\pi]$, which is a (potentially weighted) sum of all future rewards that the agent will obtain under the greedy policy. Because we've already specified our rewards implicitly in the various reward functions we defined above, we will run into trouble if we use softmax. Indeed, $0\\le \\text{softmax}(x)\\le 1$, whereas our reward functions can tske all sorts of integer values, sometimes negative. Thus is makes more sense to use `ReLU` or `LeakyReLU` for activation in our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be6763a2-8d26-400b-abaf-adf625ff1e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_tensor(index, length):\n",
    "    assert isinstance(index, int)\n",
    "    assert isinstance(length, int)\n",
    "    assert 0 <= index <= length\n",
    "    \n",
    "    onehot = torch.Tensor([float(i == index) for i in range(length)])\n",
    "    \n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f47210f-d07a-461d-a4a8-6723203be546",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionValue_01(nn.Module):\n",
    "    def __init__(self,\n",
    "                 chord_size = 3,\n",
    "                 lower_limit = 0,\n",
    "                 upper_limit = 5,\n",
    "                 layer_count = 8,\n",
    "                 layer_features = 1000):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.chord_size = chord_size\n",
    "        self.lower_limit = lower_limit\n",
    "        self.upper_limit = upper_limit\n",
    "        \n",
    "        self.random_chord = RandomChord(chord_size = self.chord_size,\n",
    "                                        lower_limit = self.lower_limit,\n",
    "                                        upper_limit = self.upper_limit)\n",
    "        \n",
    "        self.admissible_chord_count = len(self.random_chord.admissible_chords)\n",
    "        \n",
    "        self.index_to_chord = {i: chord for i, chord in enumerate(self.random_chord.admissible_chords)}\n",
    "        self.chord_to_index = {tuple(chord): i for i, chord in enumerate(self.random_chord.admissible_chords)}\n",
    "        self.chord_to_tensor = {tuple(chord): onehot_tensor(index, self.admissible_chord_count) \\\n",
    "                                for index, chord in enumerate(self.random_chord.admissible_chords)}\n",
    "        \n",
    "        \n",
    "        assert isinstance(layer_count, int)\n",
    "        assert layer_count > 0\n",
    "        assert isinstance(layer_features, int)\n",
    "        assert layer_features > 0\n",
    "        \n",
    "        self.layer_count = layer_count\n",
    "        self.layer_features = layer_features\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        # Critical here: the `3` in our `in_features = 3 * self.admissible_chord_count` comes from:\n",
    "        # 0: current state\n",
    "        # 1: next state\n",
    "        # 2: final (goal) state\n",
    "        # The action variable here is implict in the assignment `step current state ← next state`\n",
    "        self.layers.append(nn.Linear(in_features = 3 * self.admissible_chord_count, out_features = self.layer_features))\n",
    "        for k in range(self.layer_count-2):\n",
    "            self.layers.append(nn.Linear(in_features = self.layer_features, out_features = self.layer_features))\n",
    "        self.layers.append(nn.Linear(in_features = self.layer_features, out_features = 1))\n",
    "        \n",
    "        self.activation = nn.ELU()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = x\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            #print(i)\n",
    "            activated_features = self.activation(features)\n",
    "            features = layer(activated_features)\n",
    "            \n",
    "        return features\n",
    "    \n",
    "    \n",
    "    def greedy_action(self, chord_0, final_chord):\n",
    "        assert isinstance(chord_0, list)\n",
    "        assert isinstance(final_chord, list)\n",
    "        assert len(chord_0) == len(final_chord) == self.random_chord.chord_size\n",
    "        for i in range(self.random_chord.chord_size):\n",
    "            assert isinstance(chord_0[i], int)\n",
    "            assert self.random_chord.lower_limit <= chord_0[i] <= self.random_chord.upper_limit\n",
    "            assert isinstance(final_chord[i], int)\n",
    "            assert self.random_chord.lower_limit <= final_chord[i] <= self.random_chord.upper_limit\n",
    "            \n",
    "        onehot_0 = self.chord_to_tensor[tuple(chord_0)]\n",
    "        final_onehot = self.chord_to_tensor[tuple(final_chord)]\n",
    "\n",
    "        max_index = -math.inf\n",
    "        for index in range(self.admissible_chord_count):\n",
    "            test_chord = self.index_to_chord[index]\n",
    "            test_onehot = self.chord_to_tensor[tuple(test_chord)]\n",
    "            \n",
    "            model_input = torch.cat((onehot_0,\n",
    "                                     test_onehot,\n",
    "                                     final_onehot))\n",
    "            \n",
    "            model_output = self.forward(model_input)\n",
    "            \n",
    "            if model_output.item() > max_index:\n",
    "                max_index = model_output.item()\n",
    "                chord_that_maximizes = test_chord\n",
    "                \n",
    "        return chord_that_maximizes\n",
    "    \n",
    "    \n",
    "    def epsilon_greedy_action(self, epsilon, chord_0, final_chord):\n",
    "        assert isinstance(epsilon, float)\n",
    "        assert 0.0 <= epsilon <= 1.0\n",
    "        \n",
    "        greedy_or_random = np.random.choice(['greedy', 'random'], p=[1-epsilon, epsilon])\n",
    "        \n",
    "        if greedy_or_random == 'greedy':\n",
    "            output_chord = self.greedy_action(chord_0, final_chord)\n",
    "        elif greedy_or_random == 'random':\n",
    "            output_chord = self.random_chord.sample()\n",
    "        \n",
    "        return output_chord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a29e88-6e20-49bb-96a0-9c6f975de891",
   "metadata": {},
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd404a2f-2c6d-4aa4-a6f7-801566cf7dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0072], grad_fn=<AddBackward0>)\n",
      "[36, 54, 57]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:22<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050000000000000044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "action_value = ActionValue_01(chord_size = 3,\n",
    "                              lower_limit = 36,\n",
    "                              upper_limit = 60,\n",
    "                              layer_count = 4,\n",
    "                              layer_features = 500)\n",
    "\n",
    "x = torch.rand(3 * action_value.admissible_chord_count)\n",
    "print(action_value(x))\n",
    "\n",
    "g_a = action_value.greedy_action([36, 38, 40], [37, 39, 44])\n",
    "print(g_a)\n",
    "\n",
    "trial_count = 20\n",
    "eps = 0\n",
    "for i in tqdm(range(trial_count)):\n",
    "    e_g_a = action_value.epsilon_greedy_action(.1, [36, 38, 40], [37, 39, 44])\n",
    "    if e_g_a == g_a:\n",
    "        eps += 1\n",
    "print(1-(eps/trial_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9578384d-6719-4610-881e-af68200dd0d1",
   "metadata": {},
   "source": [
    "### \"First species\" voice leading reinforcement learning agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5806ac6b",
   "metadata": {},
   "source": [
    "#### Class: `Agent_01`\n",
    "\n",
    "Constructor arguments:\n",
    "* *action_value* = `ActionValue_01`, \n",
    "* *start_chord* = `[0, 1, 2]`, \n",
    "* *end_chord* = `[3, 4, 5]`, \n",
    "\n",
    "**What it does.** \n",
    "\n",
    "**Remark: Tips for future `Agent_##`s.** I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a22eba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent_01():\n",
    "    def __init__(self,\n",
    "                 action_value = ActionValue_01(),\n",
    "                 start_chord = [0, 1, 2],\n",
    "                 final_chord = [3, 4, 5]):\n",
    "        \n",
    "        assert isinstance(action_value, ActionValue_01)\n",
    "        \n",
    "        self.action_value = action_value\n",
    "        \n",
    "        self.chord_size = self.action_value.random_chord.chord_size\n",
    "        \n",
    "        self.lower_limit = self.action_value.random_chord.lower_limit\n",
    "        self.upper_limit = self.action_value.random_chord.upper_limit\n",
    "        \n",
    "        self.chord_to_tensor = self.action_value.chord_to_tensor\n",
    "        \n",
    "        assert isinstance(start_chord, list)\n",
    "        assert isinstance(final_chord, list)\n",
    "        assert len(start_chord) == len(final_chord) == self.chord_size\n",
    "        for i in range(self.chord_size):\n",
    "            assert isinstance(start_chord[i], int)\n",
    "            assert isinstance(final_chord[i], int)\n",
    "            assert self.lower_limit <= start_chord[i] <= self.upper_limit\n",
    "            assert self.lower_limit <= final_chord[i] <= self.upper_limit\n",
    "        \n",
    "        self.start_chord = start_chord\n",
    "        self.start_tensor = self.chord_to_tensor[tuple(self.start_chord)]\n",
    "        \n",
    "        self.final_chord = final_chord\n",
    "        self.final_tensor = self.chord_to_tensor[tuple(self.final_chord)]\n",
    "        \n",
    "        self.chord_episode = [self.start_chord]\n",
    "        self.tensor_episode = [self.start_tensor]\n",
    "        \n",
    "        self.small_prog_to_fin_scheme = SmallProgtoFinSchema()\n",
    "        \n",
    "        \n",
    "    def next_interval(self, epsilon = 0.1):\n",
    "        chord_0 = self.chord_episode[-1]\n",
    "        \n",
    "        next_chord = action_value.epsilon_greedy_action(epsilon, chord_0, self.final_chord)\n",
    "        next_tensor = self.chord_to_tensor[tuple(next_chord)]\n",
    "        \n",
    "        self.chord_episode.append(next_chord)\n",
    "        self.tensor_episode.append(next_tensor)\n",
    "    \n",
    "\n",
    "    def last_reward(self):\n",
    "        assert len(self.chord_episode) > 1\n",
    "        \n",
    "        last_chord = self.chord_episode[-2]\n",
    "        last_action = self.chord_episode[-1]\n",
    "        \n",
    "        if last_action == self.final_chord:\n",
    "            reward = 1000.0\n",
    "        else:\n",
    "            reward = self.small_prog_to_fin_scheme.reward(chord_0 = np.array(last_chord),\n",
    "                                                          chord_1 = np.array(last_action),\n",
    "                                                          final_chord = np.array(self.final_chord))\n",
    "            \n",
    "        return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c5c1b",
   "metadata": {},
   "source": [
    "Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27c0bdbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0., 0., 0.,  ..., 0., 0., 0.])] \n",
      "\n",
      "[tensor([0., 0., 0.,  ..., 0., 0., 0.]), tensor([0., 0., 0.,  ..., 0., 0., 0.])]\n",
      "0.2 \n",
      "\n",
      "[tensor([0., 0., 0.,  ..., 0., 0., 0.]), tensor([0., 0., 0.,  ..., 0., 0., 0.]), tensor([0., 0., 0.,  ..., 0., 0., 0.])]\n",
      "-100.0 \n",
      "\n",
      "[tensor([0., 0., 0.,  ..., 0., 0., 0.]), tensor([0., 0., 0.,  ..., 0., 0., 0.]), tensor([0., 0., 0.,  ..., 0., 0., 0.]), tensor([0., 0., 0.,  ..., 0., 0., 0.])]\n",
      "-100.0 \n",
      "\n",
      "[tensor([0., 0., 0.,  ..., 0., 0., 0.]), tensor([0., 0., 0.,  ..., 0., 0., 0.]), tensor([0., 0., 0.,  ..., 0., 0., 0.]), tensor([0., 0., 0.,  ..., 0., 0., 0.]), tensor([0., 0., 0.,  ..., 0., 0., 0.])]\n",
      "-100.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "action_value = ActionValue_01(chord_size = 3,\n",
    "                              lower_limit = 36,\n",
    "                              upper_limit = 60,\n",
    "                              layer_count = 4,\n",
    "                              layer_features = 500)\n",
    "\n",
    "agent = Agent_01(action_value = action_value,\n",
    "                 start_chord = [36, 38, 40],\n",
    "                 final_chord = [37, 39, 44])\n",
    "\n",
    "print(agent.tensor_episode, '\\n')\n",
    "\n",
    "agent.next_interval()\n",
    "print(agent.tensor_episode)\n",
    "print(agent.last_reward(), '\\n')\n",
    "\n",
    "agent.next_interval()\n",
    "print(agent.tensor_episode)\n",
    "print(agent.last_reward(), '\\n')\n",
    "\n",
    "agent.next_interval()\n",
    "print(agent.tensor_episode)\n",
    "print(agent.last_reward(), '\\n')\n",
    "\n",
    "agent.next_interval()\n",
    "print(agent.tensor_episode)\n",
    "print(agent.last_reward(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca52481-dccd-4fb3-8b30-1bd0b3cf638f",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f2de56-540e-43a8-b58a-29923190cc58",
   "metadata": {},
   "source": [
    "## Training loop(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37554400-e971-4bc3-a891-7d52b938d52d",
   "metadata": {},
   "source": [
    "### Attempt 1.\n",
    "#### Verdict(s): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86cd00f1-b69a-4e3f-8689-f86685221b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48]]\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "action_value = ActionValue_01(chord_size = 1,\n",
    "                              lower_limit = 36,\n",
    "                              upper_limit = 48,\n",
    "                              layer_count = 5,\n",
    "                              layer_features = 100)\n",
    "\n",
    "print(action_value.random_chord.admissible_chords)\n",
    "print(len(action_value.random_chord.admissible_chords))\n",
    "\n",
    "agent = Agent_01(action_value = action_value,\n",
    "                 start_chord = [36],\n",
    "                 final_chord = [39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2f1f456-e732-46ac-a6db-cae1036a8fa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                         | 1/10000 [00:00<26:59,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsiode count: 0 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 1.0\n",
      "Average loss: 78802.21589396788\n",
      "Actions per episode: 83.0\n",
      "Epsiode count: 1 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 1.0\n",
      "Average loss: 1951445.5\n",
      "Actions per episode: 42.5\n",
      "Epsiode count: 2 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                         | 4/10000 [00:00<11:41, 14.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 1.0\n",
      "Average loss: 151404.3881854672\n",
      "Actions per episode: 41.333333333333336\n",
      "Epsiode count: 3 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 1.0\n",
      "Average loss: 154474.00364783642\n",
      "Actions per episode: 40.25\n",
      "Epsiode count: 4 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 1.0\n",
      "Average loss: 346025.3376459414\n",
      "Actions per episode: 35.2\n",
      "Epsiode count: 5 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 1.0\n",
      "Average loss: 376974.66891334736\n",
      "Actions per episode: 31.5\n",
      "Epsiode count: 6 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                         | 9/10000 [00:00<10:57, 15.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 1.0\n",
      "Average loss: 88482.47525822461\n",
      "Actions per episode: 36.285714285714285\n",
      "Epsiode count: 7 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 1.0\n",
      "Average loss: 97458.22467444938\n",
      "Actions per episode: 39.0\n",
      "Epsiode count: 8 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 1.0\n",
      "Average loss: 309883.1791539727\n",
      "Actions per episode: 36.44444444444444\n",
      "Epsiode count: 9 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 1.0\n",
      "Average loss: 2014890.875\n",
      "Actions per episode: 32.9\n",
      "Epsiode count: 10 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 12/10000 [00:00<11:48, 14.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 1.0\n",
      "Average loss: 113829.03996726393\n",
      "Actions per episode: 34.0\n",
      "Epsiode count: 11 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 1.0\n",
      "Average loss: 66888.29246556846\n",
      "Actions per episode: 38.25\n",
      "Epsiode count: 12 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 14/10000 [00:01<14:27, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 1.0\n",
      "Average loss: 62151.689068076645\n",
      "Actions per episode: 42.53846153846154\n",
      "Epsiode count: 13 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 1.0\n",
      "Average loss: 119120.02790651533\n",
      "Actions per episode: 42.857142857142854\n",
      "Epsiode count: 14 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 1.0\n",
      "Average loss: 2106221.75\n",
      "Actions per episode: 40.06666666666667\n",
      "Epsiode count: 15 \n",
      "\n",
      "Goals per spisode: 0.9375\n",
      "Average loss: 0.0\n",
      "Actions per episode: 37.5625\n",
      "Epsiode count: 16 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9411764705882353\n",
      "Average loss: 340475.19162069884\n",
      "Actions per episode: 36.1764705882353\n",
      "Epsiode count: 17 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9444444444444444\n",
      "Average loss: 543780.4444444445\n",
      "Actions per episode: 34.611111111111114\n",
      "Epsiode count: 18 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 23/10000 [00:01<10:02, 16.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9473684210526315\n",
      "Average loss: 48263.73321018249\n",
      "Actions per episode: 39.1578947368421\n",
      "Epsiode count: 19 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.95\n",
      "Average loss: 176490.74495197576\n",
      "Actions per episode: 38.6\n",
      "Epsiode count: 20 \n",
      "\n",
      "Goals per spisode: 0.9047619047619048\n",
      "Average loss: 0.0\n",
      "Actions per episode: 36.76190476190476\n",
      "Epsiode count: 21 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9090909090909091\n",
      "Average loss: 251811.68700085432\n",
      "Actions per episode: 35.95454545454545\n",
      "Epsiode count: 22 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9130434782608695\n",
      "Average loss: 88791.0120340222\n",
      "Actions per episode: 36.91304347826087\n",
      "Epsiode count: 23 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 30/10000 [00:01<08:10, 20.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9166666666666666\n",
      "Average loss: 90090.54704696313\n",
      "Actions per episode: 37.75\n",
      "Epsiode count: 24 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.92\n",
      "Average loss: 185183.21194305643\n",
      "Actions per episode: 37.28\n",
      "Epsiode count: 25 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9230769230769231\n",
      "Average loss: 1833638.625\n",
      "Actions per episode: 35.88461538461539\n",
      "Epsiode count: 26 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9259259259259259\n",
      "Average loss: 1481745.4166666667\n",
      "Actions per episode: 34.629629629629626\n",
      "Epsiode count: 27 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9285714285714286\n",
      "Average loss: 213932.25983792543\n",
      "Actions per episode: 34.107142857142854\n",
      "Epsiode count: 28 \n",
      "\n",
      "Goals per spisode: 0.896551724137931\n",
      "Average loss: 0.0\n",
      "Actions per episode: 32.93103448275862\n",
      "Epsiode count: 29 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9\n",
      "Average loss: 82090.70433616417\n",
      "Actions per episode: 33.766666666666666\n",
      "Epsiode count: 30 \n",
      "\n",
      "Goals per spisode: 0.8709677419354839\n",
      "Average loss: 0.0\n",
      "Actions per episode: 32.67741935483871\n",
      "Epsiode count: 31 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.875\n",
      "Average loss: 90510.50769122646\n",
      "Actions per episode: 33.25\n",
      "Epsiode count: 32 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8787878787878788\n",
      "Average loss: 1644724.125\n",
      "Actions per episode: 32.27272727272727\n",
      "Epsiode count: 33 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                       | 37/10000 [00:02<10:18, 16.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8823529411764706\n",
      "Average loss: 34473.8549655864\n",
      "Actions per episode: 36.205882352941174\n",
      "Epsiode count: 34 \n",
      "\n",
      "Goals per spisode: 0.8571428571428571\n",
      "Average loss: 0.0\n",
      "Actions per episode: 35.17142857142857\n",
      "Epsiode count: 35 \n",
      "\n",
      "Goals per spisode: 0.8333333333333334\n",
      "Average loss: 0.0\n",
      "Actions per episode: 34.19444444444444\n",
      "Epsiode count: 36 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8378378378378378\n",
      "Average loss: 58862.7368940957\n",
      "Actions per episode: 35.83783783783784\n",
      "Epsiode count: 37 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8421052631578947\n",
      "Average loss: 439607.02477375924\n",
      "Actions per episode: 35.1578947368421\n",
      "Epsiode count: 38 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                       | 39/10000 [00:02<13:10, 12.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8461538461538461\n",
      "Average loss: 39782.190865264725\n",
      "Actions per episode: 38.30769230769231\n",
      "Epsiode count: 39 \n",
      "\n",
      "Goals per spisode: 0.825\n",
      "Average loss: 0.0\n",
      "Actions per episode: 37.35\n",
      "Epsiode count: 40 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8292682926829268\n",
      "Average loss: 221509.87210856937\n",
      "Actions per episode: 37.0\n",
      "Epsiode count: 41 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8333333333333334\n",
      "Average loss: 247581.59913333258\n",
      "Actions per episode: 36.595238095238095\n",
      "Epsiode count: 42 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8372093023255814\n",
      "Average loss: 1948434.375\n",
      "Actions per episode: 35.76744186046512\n",
      "Epsiode count: 43 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                       | 46/10000 [00:03<11:32, 14.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8409090909090909\n",
      "Average loss: 54263.11728654272\n",
      "Actions per episode: 37.40909090909091\n",
      "Epsiode count: 44 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8444444444444444\n",
      "Average loss: 1000187.35\n",
      "Actions per episode: 36.666666666666664\n",
      "Epsiode count: 45 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8478260869565217\n",
      "Average loss: 76247.14305361167\n",
      "Actions per episode: 37.43478260869565\n",
      "Epsiode count: 46 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                       | 51/10000 [00:03<11:04, 14.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.851063829787234\n",
      "Average loss: 49913.8132611812\n",
      "Actions per episode: 39.276595744680854\n",
      "Epsiode count: 47 \n",
      "\n",
      "Goals per spisode: 0.8333333333333334\n",
      "Average loss: 0.0\n",
      "Actions per episode: 38.458333333333336\n",
      "Epsiode count: 48 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8367346938775511\n",
      "Average loss: 314347.5127431277\n",
      "Actions per episode: 38.0\n",
      "Epsiode count: 49 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.84\n",
      "Average loss: 184962.12068965516\n",
      "Actions per episode: 37.8\n",
      "Epsiode count: 50 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8431372549019608\n",
      "Average loss: 156896.96600024018\n",
      "Actions per episode: 37.68627450980392\n",
      "Epsiode count: 51 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8461538461538461\n",
      "Average loss: 192037.36906491048\n",
      "Actions per episode: 37.44230769230769\n",
      "Epsiode count: 52 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                       | 53/10000 [00:03<11:54, 13.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8490566037735849\n",
      "Average loss: 73644.33314537848\n",
      "Actions per episode: 38.132075471698116\n",
      "Epsiode count: 53 \n",
      "\n",
      "Goals per spisode: 0.8333333333333334\n",
      "Average loss: 0.0\n",
      "Actions per episode: 37.425925925925924\n",
      "Epsiode count: 54 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                       | 58/10000 [00:04<13:32, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8363636363636363\n",
      "Average loss: 35483.995031827195\n",
      "Actions per episode: 40.4\n",
      "Epsiode count: 55 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8392857142857143\n",
      "Average loss: 332963.2120057003\n",
      "Actions per episode: 39.964285714285715\n",
      "Epsiode count: 56 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8421052631578947\n",
      "Average loss: 218543.79752257752\n",
      "Actions per episode: 39.70175438596491\n",
      "Epsiode count: 57 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8448275862068966\n",
      "Average loss: 109561.5084726878\n",
      "Actions per episode: 39.91379310344828\n",
      "Epsiode count: 58 \n",
      "\n",
      "Goals per spisode: 0.8305084745762712\n",
      "Average loss: 0.0\n",
      "Actions per episode: 39.23728813559322\n",
      "Epsiode count: 59 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8333333333333334\n",
      "Average loss: 338488.2803065926\n",
      "Actions per episode: 38.833333333333336\n",
      "Epsiode count: 60 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                       | 62/10000 [00:04<10:30, 15.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8360655737704918\n",
      "Average loss: 136476.36474927998\n",
      "Actions per episode: 38.83606557377049\n",
      "Epsiode count: 61 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8387096774193549\n",
      "Average loss: 174069.71600202768\n",
      "Actions per episode: 38.67741935483871\n",
      "Epsiode count: 62 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8412698412698413\n",
      "Average loss: 695193.3462325803\n",
      "Actions per episode: 38.15873015873016\n",
      "Epsiode count: 63 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.84375\n",
      "Average loss: 932010.8\n",
      "Actions per episode: 37.625\n",
      "Epsiode count: 64 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8461538461538461\n",
      "Average loss: 126410.86934855444\n",
      "Actions per episode: 37.61538461538461\n",
      "Epsiode count: 65 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                       | 66/10000 [00:04<09:15, 17.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8484848484848485\n",
      "Average loss: 93343.88226586889\n",
      "Actions per episode: 37.81818181818182\n",
      "Epsiode count: 66 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8507462686567164\n",
      "Average loss: 111411.17362241256\n",
      "Actions per episode: 37.88059701492537\n",
      "Epsiode count: 67 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                       | 73/10000 [00:04<08:29, 19.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8529411764705882\n",
      "Average loss: 49678.838593104556\n",
      "Actions per episode: 38.85294117647059\n",
      "Epsiode count: 68 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.855072463768116\n",
      "Average loss: 1779058.0\n",
      "Actions per episode: 38.30434782608695\n",
      "Epsiode count: 69 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8571428571428571\n",
      "Average loss: 1707981.5\n",
      "Actions per episode: 37.77142857142857\n",
      "Epsiode count: 70 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8591549295774648\n",
      "Average loss: 161299.02325191468\n",
      "Actions per episode: 37.61971830985915\n",
      "Epsiode count: 71 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8611111111111112\n",
      "Average loss: 255073.16748565633\n",
      "Actions per episode: 37.31944444444444\n",
      "Epsiode count: 72 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.863013698630137\n",
      "Average loss: 225724.19736842104\n",
      "Actions per episode: 37.054794520547944\n",
      "Epsiode count: 73 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8648648648648649\n",
      "Average loss: 73867.0749424851\n",
      "Actions per episode: 37.37837837837838\n",
      "Epsiode count: 74 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8666666666666667\n",
      "Average loss: 44604.579962036376\n",
      "Actions per episode: 38.36\n",
      "Epsiode count: 75 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                       | 78/10000 [00:05<12:06, 13.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.868421052631579\n",
      "Average loss: 77993.25685234918\n",
      "Actions per episode: 38.64473684210526\n",
      "Epsiode count: 76 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8701298701298701\n",
      "Average loss: 77691.63152740622\n",
      "Actions per episode: 38.96103896103896\n",
      "Epsiode count: 77 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8717948717948718\n",
      "Average loss: 318922.7189140501\n",
      "Actions per episode: 38.62820512820513\n",
      "Epsiode count: 78 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                       | 82/10000 [00:05<11:02, 14.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8734177215189873\n",
      "Average loss: 80739.22700859758\n",
      "Actions per episode: 38.87341772151899\n",
      "Epsiode count: 79 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.875\n",
      "Average loss: 1057813.4375\n",
      "Actions per episode: 38.425\n",
      "Epsiode count: 80 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8765432098765432\n",
      "Average loss: 317208.4308361319\n",
      "Actions per episode: 38.098765432098766\n",
      "Epsiode count: 81 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8780487804878049\n",
      "Average loss: 77413.25788026127\n",
      "Actions per episode: 38.31707317073171\n",
      "Epsiode count: 82 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                       | 84/10000 [00:05<10:27, 15.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8795180722891566\n",
      "Average loss: 74504.28401374258\n",
      "Actions per episode: 38.54216867469879\n",
      "Epsiode count: 83 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8809523809523809\n",
      "Average loss: 434781.91794139147\n",
      "Actions per episode: 38.17857142857143\n",
      "Epsiode count: 84 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8823529411764706\n",
      "Average loss: 46067.20339956621\n",
      "Actions per episode: 38.870588235294115\n",
      "Epsiode count: 85 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                       | 88/10000 [00:06<11:37, 14.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8837209302325582\n",
      "Average loss: 184663.74567930028\n",
      "Actions per episode: 38.66279069767442\n",
      "Epsiode count: 86 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8850574712643678\n",
      "Average loss: 109413.07057086247\n",
      "Actions per episode: 38.632183908045974\n",
      "Epsiode count: 87 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8863636363636364\n",
      "Average loss: 104879.695590684\n",
      "Actions per episode: 38.61363636363637\n",
      "Epsiode count: 88 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8876404494382022\n",
      "Average loss: 133051.56212113952\n",
      "Actions per episode: 38.49438202247191\n",
      "Epsiode count: 89 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                       | 90/10000 [00:06<14:31, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8888888888888888\n",
      "Average loss: 44079.937422157585\n",
      "Actions per episode: 39.31111111111111\n",
      "Epsiode count: 90 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8901098901098901\n",
      "Average loss: 80002.49179218858\n",
      "Actions per episode: 39.472527472527474\n",
      "Epsiode count: 91 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                       | 92/10000 [00:06<16:51,  9.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8913043478260869\n",
      "Average loss: 48206.076039199834\n",
      "Actions per episode: 40.15217391304348\n",
      "Epsiode count: 92 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8924731182795699\n",
      "Average loss: 1382756.0\n",
      "Actions per episode: 39.74193548387097\n",
      "Epsiode count: 93 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8936170212765957\n",
      "Average loss: 231783.07253161736\n",
      "Actions per episode: 39.5\n",
      "Epsiode count: 94 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                       | 96/10000 [00:07<20:21,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8947368421052632\n",
      "Average loss: 24532.79445878531\n",
      "Actions per episode: 41.77894736842105\n",
      "Epsiode count: 95 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8958333333333334\n",
      "Average loss: 81964.59848471037\n",
      "Actions per episode: 42.010416666666664\n",
      "Epsiode count: 96 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8969072164948454\n",
      "Average loss: 370604.47968884156\n",
      "Actions per episode: 41.70103092783505\n",
      "Epsiode count: 97 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                       | 98/10000 [00:07<18:08,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.8979591836734694\n",
      "Average loss: 71487.0274229678\n",
      "Actions per episode: 42.03061224489796\n",
      "Epsiode count: 98 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.898989898989899\n",
      "Average loss: 51639.84106730687\n",
      "Actions per episode: 42.656565656565654\n",
      "Epsiode count: 99 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 103/10000 [00:07<14:11, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9\n",
      "Average loss: 152130.2693160209\n",
      "Actions per episode: 42.55\n",
      "Epsiode count: 100 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.900990099009901\n",
      "Average loss: 146819.26924211314\n",
      "Actions per episode: 42.45544554455446\n",
      "Epsiode count: 101 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9019607843137255\n",
      "Average loss: 359166.94808490376\n",
      "Actions per episode: 42.15686274509804\n",
      "Epsiode count: 102 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9029126213592233\n",
      "Average loss: 107677.34684606007\n",
      "Actions per episode: 42.16504854368932\n",
      "Epsiode count: 103 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 105/10000 [00:08<17:18,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9038461538461539\n",
      "Average loss: 53366.64808173368\n",
      "Actions per episode: 42.75961538461539\n",
      "Epsiode count: 104 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9047619047619048\n",
      "Average loss: 76195.97394399335\n",
      "Actions per episode: 43.00952380952381\n",
      "Epsiode count: 105 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9056603773584906\n",
      "Average loss: 303099.40972561203\n",
      "Actions per episode: 42.74528301886792\n",
      "Epsiode count: 106 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9065420560747663\n",
      "Average loss: 289370.315255885\n",
      "Actions per episode: 42.48598130841121\n",
      "Epsiode count: 107 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 110/10000 [00:08<18:03,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9074074074074074\n",
      "Average loss: 30858.270512538966\n",
      "Actions per episode: 44.092592592592595\n",
      "Epsiode count: 108 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.908256880733945\n",
      "Average loss: 145022.00016456575\n",
      "Actions per episode: 44.03669724770642\n",
      "Epsiode count: 109 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9090909090909091\n",
      "Average loss: 116316.83139440946\n",
      "Actions per episode: 44.06363636363636\n",
      "Epsiode count: 110 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 112/10000 [00:08<16:46,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9099099099099099\n",
      "Average loss: 99898.38841009566\n",
      "Actions per episode: 44.16216216216216\n",
      "Epsiode count: 111 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9107142857142857\n",
      "Average loss: 149241.9806905699\n",
      "Actions per episode: 44.089285714285715\n",
      "Epsiode count: 112 \n",
      "\n",
      "Goals per spisode: 0.9026548672566371\n",
      "Average loss: 0.0\n",
      "Actions per episode: 43.69911504424779\n",
      "Epsiode count: 113 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9035087719298246\n",
      "Average loss: 95844.6871003974\n",
      "Actions per episode: 43.80701754385965\n",
      "Epsiode count: 114 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 118/10000 [00:09<12:18, 13.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9043478260869565\n",
      "Average loss: 76277.06673556684\n",
      "Actions per episode: 44.07826086956522\n",
      "Epsiode count: 115 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9051724137931034\n",
      "Average loss: 570659.4761132813\n",
      "Actions per episode: 43.76724137931034\n",
      "Epsiode count: 116 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.905982905982906\n",
      "Average loss: 1215808.1875\n",
      "Actions per episode: 43.41880341880342\n",
      "Epsiode count: 117 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9067796610169492\n",
      "Average loss: 78919.5306288511\n",
      "Actions per episode: 43.610169491525426\n",
      "Epsiode count: 118 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.907563025210084\n",
      "Average loss: 89023.14188339046\n",
      "Actions per episode: 43.739495798319325\n",
      "Epsiode count: 119 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 123/10000 [00:09<15:27, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9083333333333333\n",
      "Average loss: 38522.13429074776\n",
      "Actions per episode: 44.86666666666667\n",
      "Epsiode count: 120 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9090909090909091\n",
      "Average loss: 187104.09013883962\n",
      "Actions per episode: 44.743801652892564\n",
      "Epsiode count: 121 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9098360655737705\n",
      "Average loss: 237812.94431344324\n",
      "Actions per episode: 44.557377049180324\n",
      "Epsiode count: 122 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9105691056910569\n",
      "Average loss: 109373.59392094846\n",
      "Actions per episode: 44.60162601626016\n",
      "Epsiode count: 123 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9112903225806451\n",
      "Average loss: 37860.31693897085\n",
      "Actions per episode: 45.70161290322581\n",
      "Epsiode count: 124 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                      | 127/10000 [00:10<18:50,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.912\n",
      "Average loss: 53336.8346836929\n",
      "Actions per episode: 46.352\n",
      "Epsiode count: 125 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9126984126984127\n",
      "Average loss: 144597.63638208297\n",
      "Actions per episode: 46.32539682539682\n",
      "Epsiode count: 126 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9133858267716536\n",
      "Average loss: 301296.9199258007\n",
      "Actions per episode: 46.110236220472444\n",
      "Epsiode count: 127 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9140625\n",
      "Average loss: 266140.87745729496\n",
      "Actions per episode: 45.9140625\n",
      "Epsiode count: 128 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                      | 134/10000 [00:10<10:10, 16.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9147286821705426\n",
      "Average loss: 133693.7132496824\n",
      "Actions per episode: 45.89922480620155\n",
      "Epsiode count: 129 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9153846153846154\n",
      "Average loss: 127962.20286347393\n",
      "Actions per episode: 45.89230769230769\n",
      "Epsiode count: 130 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.916030534351145\n",
      "Average loss: 1791844.1666666667\n",
      "Actions per episode: 45.55725190839695\n",
      "Epsiode count: 131 \n",
      "\n",
      "Goals per spisode: 0.9090909090909091\n",
      "Average loss: 0.0\n",
      "Actions per episode: 45.21212121212121\n",
      "Epsiode count: 132 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9097744360902256\n",
      "Average loss: 520908.29525499494\n",
      "Actions per episode: 44.93984962406015\n",
      "Epsiode count: 133 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9104477611940298\n",
      "Average loss: 555793.6111111111\n",
      "Actions per episode: 44.66417910447761\n",
      "Epsiode count: 134 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9111111111111111\n",
      "Average loss: 60193.42699312317\n",
      "Actions per episode: 45.02962962962963\n",
      "Epsiode count: 135 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9117647058823529\n",
      "Average loss: 84070.89855673286\n",
      "Actions per episode: 45.18382352941177\n",
      "Epsiode count: 136 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                      | 137/10000 [00:11<14:11, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9124087591240876\n",
      "Average loss: 73168.20195545656\n",
      "Actions per episode: 45.43065693430657\n",
      "Epsiode count: 137 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9130434782608695\n",
      "Average loss: 401919.9836007632\n",
      "Actions per episode: 45.18840579710145\n",
      "Epsiode count: 138 \n",
      "\n",
      "Goals per spisode: 0.9064748201438849\n",
      "Average loss: 0.0\n",
      "Actions per episode: 44.86330935251799\n",
      "Epsiode count: 139 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                      | 143/10000 [00:11<13:06, 12.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9071428571428571\n",
      "Average loss: 47241.88490518392\n",
      "Actions per episode: 45.56428571428572\n",
      "Epsiode count: 140 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9078014184397163\n",
      "Average loss: 191817.6382576724\n",
      "Actions per episode: 45.4468085106383\n",
      "Epsiode count: 141 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9084507042253521\n",
      "Average loss: 324156.39637454203\n",
      "Actions per episode: 45.23943661971831\n",
      "Epsiode count: 142 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9090909090909091\n",
      "Average loss: 115184.87685816135\n",
      "Actions per episode: 45.27272727272727\n",
      "Epsiode count: 143 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                      | 145/10000 [00:11<12:41, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9097222222222222\n",
      "Average loss: 155706.79460687024\n",
      "Actions per episode: 45.201388888888886\n",
      "Epsiode count: 144 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9103448275862069\n",
      "Average loss: 123067.76068329712\n",
      "Actions per episode: 45.19310344827586\n",
      "Epsiode count: 145 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.910958904109589\n",
      "Average loss: 100634.21744619441\n",
      "Actions per episode: 45.26712328767123\n",
      "Epsiode count: 146 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                      | 151/10000 [00:11<09:55, 16.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9115646258503401\n",
      "Average loss: 114569.24576531768\n",
      "Actions per episode: 45.29251700680272\n",
      "Epsiode count: 147 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9121621621621622\n",
      "Average loss: 2106434.25\n",
      "Actions per episode: 44.99324324324324\n",
      "Epsiode count: 148 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.912751677852349\n",
      "Average loss: 173240.26393872115\n",
      "Actions per episode: 44.88590604026846\n",
      "Epsiode count: 149 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9133333333333333\n",
      "Average loss: 196554.94354515924\n",
      "Actions per episode: 44.74666666666667\n",
      "Epsiode count: 150 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9139072847682119\n",
      "Average loss: 264185.8614628551\n",
      "Actions per episode: 44.562913907284766\n",
      "Epsiode count: 151 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                      | 154/10000 [00:12<10:33, 15.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9144736842105263\n",
      "Average loss: 55953.65368675143\n",
      "Actions per episode: 44.91447368421053\n",
      "Epsiode count: 152 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9150326797385621\n",
      "Average loss: 228593.22365318966\n",
      "Actions per episode: 44.751633986928105\n",
      "Epsiode count: 153 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9155844155844156\n",
      "Average loss: 1504937.3333333333\n",
      "Actions per episode: 44.47402597402598\n",
      "Epsiode count: 154 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▌                                      | 159/10000 [00:12<10:37, 15.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9161290322580645\n",
      "Average loss: 52619.774225110225\n",
      "Actions per episode: 44.83870967741935\n",
      "Epsiode count: 155 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9166666666666666\n",
      "Average loss: 163335.70833333334\n",
      "Actions per episode: 44.73717948717949\n",
      "Epsiode count: 156 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9171974522292994\n",
      "Average loss: 1771105.375\n",
      "Actions per episode: 44.45859872611465\n",
      "Epsiode count: 157 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9177215189873418\n",
      "Average loss: 229325.775\n",
      "Actions per episode: 44.29746835443038\n",
      "Epsiode count: 158 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9182389937106918\n",
      "Average loss: 112753.22449753416\n",
      "Actions per episode: 44.270440251572325\n",
      "Epsiode count: 159 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                      | 163/10000 [00:12<08:28, 19.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.91875\n",
      "Average loss: 242967.22916666666\n",
      "Actions per episode: 44.1\n",
      "Epsiode count: 160 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9192546583850931\n",
      "Average loss: 1566456.875\n",
      "Actions per episode: 43.83229813664596\n",
      "Epsiode count: 161 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9197530864197531\n",
      "Average loss: 150863.24870698995\n",
      "Actions per episode: 43.72222222222222\n",
      "Epsiode count: 162 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9202453987730062\n",
      "Average loss: 146054.9719445056\n",
      "Actions per episode: 43.61963190184049\n",
      "Epsiode count: 163 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9207317073170732\n",
      "Average loss: 123504.5170171028\n",
      "Actions per episode: 43.542682926829265\n",
      "Epsiode count: 164 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                      | 169/10000 [00:13<09:00, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9212121212121213\n",
      "Average loss: 78446.40541545113\n",
      "Actions per episode: 43.593939393939394\n",
      "Epsiode count: 165 \n",
      "\n",
      "Goals per spisode: 0.9156626506024096\n",
      "Average loss: 0.0\n",
      "Actions per episode: 43.33132530120482\n",
      "Epsiode count: 166 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9161676646706587\n",
      "Average loss: 254439.10222031275\n",
      "Actions per episode: 43.15568862275449\n",
      "Epsiode count: 167 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9166666666666666\n",
      "Average loss: 95075.46348836519\n",
      "Actions per episode: 43.13690476190476\n",
      "Epsiode count: 168 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9171597633136095\n",
      "Average loss: 80187.95787010067\n",
      "Actions per episode: 43.171597633136095\n",
      "Epsiode count: 169 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9176470588235294\n",
      "Average loss: 163744.58984451983\n",
      "Actions per episode: 43.04705882352941\n",
      "Epsiode count: 170 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9181286549707602\n",
      "Average loss: 64456.511654678914\n",
      "Actions per episode: 43.146198830409354\n",
      "Epsiode count: 171 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                      | 172/10000 [00:13<15:46, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9186046511627907\n",
      "Average loss: 25599.910379100915\n",
      "Actions per episode: 44.29651162790697\n",
      "Epsiode count: 172 \n",
      "\n",
      "Goals per spisode: 0.9132947976878613\n",
      "Average loss: 0.0\n",
      "Actions per episode: 44.040462427745666\n",
      "Epsiode count: 173 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                      | 176/10000 [00:14<15:59, 10.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9137931034482759\n",
      "Average loss: 33824.05434337048\n",
      "Actions per episode: 44.82183908045977\n",
      "Epsiode count: 174 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9142857142857143\n",
      "Average loss: 1982802.75\n",
      "Actions per episode: 44.57142857142857\n",
      "Epsiode count: 175 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9147727272727273\n",
      "Average loss: 82189.97301936065\n",
      "Actions per episode: 44.6875\n",
      "Epsiode count: 176 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9152542372881356\n",
      "Average loss: 327902.74430134345\n",
      "Actions per episode: 44.51412429378531\n",
      "Epsiode count: 177 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                      | 180/10000 [00:14<14:26, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9157303370786517\n",
      "Average loss: 114017.7116472327\n",
      "Actions per episode: 44.51123595505618\n",
      "Epsiode count: 178 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9162011173184358\n",
      "Average loss: 391508.43792205834\n",
      "Actions per episode: 44.324022346368714\n",
      "Epsiode count: 179 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9166666666666666\n",
      "Average loss: 59411.54419159456\n",
      "Actions per episode: 44.583333333333336\n",
      "Epsiode count: 180 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                      | 182/10000 [00:14<12:59, 12.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9171270718232044\n",
      "Average loss: 395748.51620596397\n",
      "Actions per episode: 44.39779005524862\n",
      "Epsiode count: 181 \n",
      "\n",
      "**********************************\n",
      "\n",
      "Goals per spisode: 0.9175824175824175\n",
      "Average loss: 99978.24784483777\n",
      "Actions per episode: 44.41208791208791\n",
      "Epsiode count: 182 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 39\u001b[0m\n\u001b[1;32m     33\u001b[0m reward_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (agent\u001b[38;5;241m.\u001b[39mchord_episode[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m agent\u001b[38;5;241m.\u001b[39mfinal_chord) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(agent\u001b[38;5;241m.\u001b[39mchord_episode) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# print('Starting chord:', random_starting_chord, '   ', 'Final goal chord:', agent.final_chord)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# print('Running state count:', len(agent.chord_episode))\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_interval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     reward \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([agent\u001b[38;5;241m.\u001b[39mlast_reward()])\n\u001b[1;32m     42\u001b[0m     reward_list\u001b[38;5;241m.\u001b[39mappend(reward)\n",
      "Cell \u001b[0;32mIn[15], line 42\u001b[0m, in \u001b[0;36mAgent_01.next_interval\u001b[0;34m(self, epsilon)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnext_interval\u001b[39m(\u001b[38;5;28mself\u001b[39m, epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m):\n\u001b[1;32m     40\u001b[0m     chord_0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchord_episode[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 42\u001b[0m     next_chord \u001b[38;5;241m=\u001b[39m \u001b[43maction_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon_greedy_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchord_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_chord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     next_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchord_to_tensor[\u001b[38;5;28mtuple\u001b[39m(next_chord)]\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchord_episode\u001b[38;5;241m.\u001b[39mappend(next_chord)\n",
      "Cell \u001b[0;32mIn[13], line 96\u001b[0m, in \u001b[0;36mActionValue_01.epsilon_greedy_action\u001b[0;34m(self, epsilon, chord_0, final_chord)\u001b[0m\n\u001b[1;32m     93\u001b[0m greedy_or_random \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreedy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m], p\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mepsilon, epsilon])\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m greedy_or_random \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreedy\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 96\u001b[0m     output_chord \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchord_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_chord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m greedy_or_random \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     98\u001b[0m     output_chord \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_chord\u001b[38;5;241m.\u001b[39msample()\n",
      "Cell \u001b[0;32mIn[13], line 80\u001b[0m, in \u001b[0;36mActionValue_01.greedy_action\u001b[0;34m(self, chord_0, final_chord)\u001b[0m\n\u001b[1;32m     74\u001b[0m test_onehot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchord_to_tensor[\u001b[38;5;28mtuple\u001b[39m(test_chord)]\n\u001b[1;32m     76\u001b[0m model_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((onehot_0,\n\u001b[1;32m     77\u001b[0m                          test_onehot,\n\u001b[1;32m     78\u001b[0m                          final_onehot))\n\u001b[0;32m---> 80\u001b[0m model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_output\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m>\u001b[39m max_index:\n\u001b[1;32m     83\u001b[0m     max_index \u001b[38;5;241m=\u001b[39m model_output\u001b[38;5;241m.\u001b[39mitem()\n",
      "Cell \u001b[0;32mIn[13], line 53\u001b[0m, in \u001b[0;36mActionValue_01.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m#print(i)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     activated_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(features)\n\u001b[0;32m---> 53\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivated_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episode_count = 10000\n",
    "present_bias = 1.0\n",
    "learning_rate = 0.0001\n",
    "\n",
    "epsilon = 0.25\n",
    "\n",
    "loss_function = nn.MSELoss().double()\n",
    "\n",
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(action_value.parameters(), lr = learning_rate)\n",
    "\n",
    "goal_count = 0\n",
    "total_actions = 0\n",
    "\n",
    "for episode_number in tqdm(range(episode_count)):\n",
    "    \n",
    "    # print('\\n________________________________________________________________________\\n')\n",
    "    \n",
    "    print('Epsiode count:', episode_number, '\\n')\n",
    "    \n",
    "    random_starting_chord = action_value.random_chord.sample()\n",
    "    starting_tensor = action_value.chord_to_tensor[tuple(random_starting_chord)]\n",
    "    \n",
    "    agent.chord_episode = [random_starting_chord]\n",
    "    agent.tensor_episode = [starting_tensor]\n",
    "    \n",
    "    agent.final_chord = action_value.random_chord.sample()\n",
    "    agent.final_tensor = agent.chord_to_tensor[tuple(agent.final_chord)]\n",
    "    \n",
    "    episode_loss = 0.0\n",
    "    action_count = 0\n",
    "    \n",
    "    reward_list = []\n",
    "    \n",
    "    while (agent.chord_episode[-1] != agent.final_chord) and (len(agent.chord_episode) <= 1000):\n",
    "        # print('Starting chord:', random_starting_chord, '   ', 'Final goal chord:', agent.final_chord)\n",
    "        # print('Running state count:', len(agent.chord_episode))\n",
    "        \n",
    "        agent.next_interval(epsilon = epsilon)\n",
    "        \n",
    "        reward = torch.Tensor([agent.last_reward()])\n",
    "        reward_list.append(reward)\n",
    "        \n",
    "        action_count += 1\n",
    "\n",
    "        if len(agent.chord_episode) >= 3:\n",
    "            \n",
    "            previous_tensor_state = agent.tensor_episode[-3]\n",
    "            present_tensor_state = agent.tensor_episode[-2]\n",
    "            next_tensor_state = agent.tensor_episode[-1]\n",
    "            \n",
    "            # print('Current chord window:', [agent.chord_episode[-3],\n",
    "            #            agent.chord_episode[-2],\n",
    "            #            agent.chord_episode[-1]])\n",
    "            \n",
    "            #print(len(previous_tensor_state))\n",
    "            #print(len(present_tensor_state))\n",
    "            #print(len(agent.final_tensor))\n",
    "            \n",
    "            previous_expected_return = action_value(torch.cat([previous_tensor_state,\n",
    "                                                               present_tensor_state,\n",
    "                                                               agent.final_tensor]))\n",
    "            \n",
    "            present_expected_return = action_value(torch.cat([present_tensor_state,\n",
    "                                                              next_tensor_state,\n",
    "                                                              agent.final_tensor]))\n",
    "            present_expected_return = torch.Tensor([present_expected_return.item()])\n",
    "            \n",
    "            present_reward = reward_list[-1]\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Compute the loss and its gradients\n",
    "            loss = loss_function(present_reward + present_bias * present_expected_return,\n",
    "                                 previous_expected_return).double()\n",
    "           \n",
    "            episode_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Adjust learning weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print('Loss at this action:', loss.item(), '\\n')\n",
    "            \n",
    "\n",
    "    if (agent.chord_episode[-1] == agent.final_chord) and len(agent.chord_episode)>1:\n",
    "        \n",
    "        goal_count += 1\n",
    "        \n",
    "        print('**********************************\\n',)\n",
    "        \n",
    "        present_tensor_state = agent.tensor_episode[-2]\n",
    "        next_tensor_state = agent.tensor_episode[-1]\n",
    "\n",
    "        present_expected_return = action_value(torch.cat([present_tensor_state,\n",
    "                                                          next_tensor_state,\n",
    "                                                          agent.final_tensor]))\n",
    "\n",
    "        present_reward = reward_list[-1]\n",
    "            \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_function(present_reward, present_expected_return).double()\n",
    "\n",
    "        episode_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "            \n",
    "        # print('Loss at this action:', loss.item(), '\\n')\n",
    "    \n",
    "    total_actions += action_count\n",
    "        \n",
    "    print('Goals per spisode:', goal_count/(1+episode_number))\n",
    "    print('Average loss:', episode_loss/(1+action_count))    \n",
    "    print('Actions per episode:', total_actions/(1+episode_number))    \n",
    "        \n",
    "     \n",
    "    # if episode_number%100 == 0:\n",
    "    #     print('Total loss this episode:', episode_loss)\n",
    "    #print('\\n', reward_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97e8ad6-47e0-45f2-8a95-6a639940804d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2345ae18-1a9e-4201-89bc-c946e430241f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422332aa-db15-450e-86f6-d9f279219d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
